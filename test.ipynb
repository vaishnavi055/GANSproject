{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13685345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from lib.config.config import cfg_from_yaml, cfg, merge_dict_and_yaml, print_easy_dict\n",
    "from lib.dataset.factory import get_dataset\n",
    "from lib.model.factory import get_model\n",
    "from lib.utils.visualizer import tensor_back_to_unnormalization, tensor_back_to_unMinMax\n",
    "from lib.utils.metrics_np import MAE, MSE, Peak_Signal_to_Noise_Rate, Structural_Similarity, Cosine_Similarity, \\\n",
    "  Peak_Signal_to_Noise_Rate_3D\n",
    "import copy\n",
    "import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983ebbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "  parse = argparse.ArgumentParser(description='CTGAN')\n",
    "  parse.add_argument('--data', type=str, default='', dest='data',\n",
    "                     help='input data ')\n",
    "  parse.add_argument('--tag', type=str, default='', dest='tag',\n",
    "                     help='distinct from other try')\n",
    "  parse.add_argument('--dataroot', type=str, default='', dest='dataroot',\n",
    "                     help='input data root')\n",
    "  parse.add_argument('--dataset', type=str, default='', dest='dataset',\n",
    "                     help='Train or test or valid')\n",
    "  parse.add_argument('--datasetfile', type=str, default='', dest='datasetfile',\n",
    "                     help='Train or test or valid file path')\n",
    "  parse.add_argument('--ymlpath', type=str, default=None, dest='ymlpath',\n",
    "                     help='config have been modified')\n",
    "  parse.add_argument('--gpu', type=str, default='0,1', dest='gpuid',\n",
    "                     help='gpu is split by ,')\n",
    "  parse.add_argument('--dataset_class', type=str, default='unalign', dest='dataset_class',\n",
    "                     help='Dataset class should select from unalign /')\n",
    "  parse.add_argument('--model_class', type=str, default='cyclegan', dest='model_class',\n",
    "                     help='Model class should select from cyclegan / ')\n",
    "  parse.add_argument('--check_point', type=str, default=None, dest='check_point',\n",
    "                     help='which epoch to load? ')\n",
    "  parse.add_argument('--latest', action='store_true', dest='latest',\n",
    "                     help='set to latest to use latest cached model')\n",
    "  parse.add_argument('--verbose', action='store_true', dest='verbose',\n",
    "                     help='if specified, print more debugging information')\n",
    "  parse.add_argument('--load_path', type=str, default=None, dest='load_path',\n",
    "                     help='if load_path is not None, model will load from load_path')\n",
    "  parse.add_argument('--how_many', type=int, dest='how_many', default=50,\n",
    "                     help='if specified, only run this number of test samples for visualization')\n",
    "  parse.add_argument('--resultdir', type=str, default='', dest='resultdir',\n",
    "                     help='dir to save result')\n",
    "  args = parse.parse_args()\n",
    "  return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63decacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(args):\n",
    "  # check gpu\n",
    "  if args.gpuid == '':\n",
    "    args.gpu_ids = []\n",
    "  else:\n",
    "    if torch.cuda.is_available():\n",
    "      split_gpu = str(args.gpuid).split(',')\n",
    "      args.gpu_ids = [int(i) for i in split_gpu]\n",
    "    else:\n",
    "      print('There is no gpu!')\n",
    "      exit(0)\n",
    "\n",
    "  # check point\n",
    "  if args.check_point is None:\n",
    "    args.epoch_count = 1\n",
    "  else:\n",
    "    args.epoch_count = int(args.check_point)\n",
    "\n",
    "  # merge config with yaml\n",
    "  if args.ymlpath is not None:\n",
    "    cfg_from_yaml(args.ymlpath)\n",
    "  # merge config with argparse\n",
    "  opt = copy.deepcopy(cfg)\n",
    "  opt = merge_dict_and_yaml(args.__dict__, opt)\n",
    "  print_easy_dict(opt)\n",
    "\n",
    "  opt.serial_batches = True\n",
    "\n",
    "  # add data_augmentation\n",
    "  datasetClass, _, dataTestClass, collateClass = get_dataset(opt.dataset_class)\n",
    "  opt.data_augmentation = dataTestClass\n",
    "\n",
    "  # get dataset\n",
    "  dataset = datasetClass(opt)\n",
    "  print('DataSet is {}'.format(dataset.name))\n",
    "  dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=int(opt.nThreads),\n",
    "    collate_fn=collateClass)\n",
    "\n",
    "  dataset_size = len(dataloader)\n",
    "  print('#Test images = %d' % dataset_size)\n",
    "\n",
    "  # get model\n",
    "  gan_model = get_model(opt.model_class)()\n",
    "  print('Model --{}-- will be Used'.format(gan_model.name))\n",
    "\n",
    "  # set to test\n",
    "  gan_model.eval()\n",
    "\n",
    "  gan_model.init_process(opt)\n",
    "  total_steps, epoch_count = gan_model.setup(opt)\n",
    "\n",
    "  # must set to test Mode again, due to  omission of assigning mode to network layers\n",
    "  # model.training is test, but BN.training is training\n",
    "  if opt.verbose:\n",
    "    print('## Model Mode: {}'.format('Training' if gan_model.training else 'Testing'))\n",
    "    for i, v in gan_model.named_modules():\n",
    "      print(i, v.training)\n",
    "\n",
    "  if 'batch' in opt.norm_G:\n",
    "    gan_model.eval()\n",
    "  elif 'instance' in opt.norm_G:\n",
    "    gan_model.eval()\n",
    "    # instance norm in training mode is better\n",
    "    for name, m in gan_model.named_modules():\n",
    "      if m.__class__.__name__.startswith('InstanceNorm'):\n",
    "        m.train()\n",
    "  else:\n",
    "    raise NotImplementedError()\n",
    "\n",
    "  if opt.verbose:\n",
    "    print('## Change to Model Mode: {}'.format('Training' if gan_model.training else 'Testing'))\n",
    "    for i, v in gan_model.named_modules():\n",
    "      print(i, v.training)\n",
    "\n",
    "  result_dir = os.path.join(opt.resultdir, opt.data, '%s_%s' % (opt.dataset, opt.check_point))\n",
    "  if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)\n",
    "\n",
    "  avg_dict = dict()\n",
    "  for epoch_i, data in tqdm.tqdm(enumerate(dataloader)):\n",
    "\n",
    "    gan_model.set_input(data)\n",
    "    gan_model.test()\n",
    "\n",
    "    visuals = gan_model.get_current_visuals()\n",
    "    img_path = gan_model.get_image_paths()\n",
    "\n",
    "    #\n",
    "    # Evaluate Part\n",
    "    #\n",
    "    generate_CT = visuals['G_fake'].data.clone().cpu().numpy()\n",
    "    real_CT = visuals['G_real'].data.clone().cpu().numpy()\n",
    "    # To [0, 1]\n",
    "    # To NDHW\n",
    "    if 'std' in opt.dataset_class or 'baseline' in opt.dataset_class:\n",
    "      generate_CT_transpose = generate_CT\n",
    "      real_CT_transpose = real_CT\n",
    "    else:\n",
    "      generate_CT_transpose = np.transpose(generate_CT, (0, 2, 1, 3))\n",
    "      real_CT_transpose = np.transpose(real_CT, (0, 2, 1, 3))\n",
    "    generate_CT_transpose = tensor_back_to_unnormalization(generate_CT_transpose, opt.CT_MEAN_STD[0],\n",
    "                                                           opt.CT_MEAN_STD[1])\n",
    "    real_CT_transpose = tensor_back_to_unnormalization(real_CT_transpose, opt.CT_MEAN_STD[0], opt.CT_MEAN_STD[1])\n",
    "    # clip generate_CT\n",
    "    generate_CT_transpose = np.clip(generate_CT_transpose, 0, 1)\n",
    "\n",
    "    # CT range 0-1\n",
    "    mae0 = MAE(real_CT_transpose, generate_CT_transpose, size_average=False)\n",
    "    mse0 = MSE(real_CT_transpose, generate_CT_transpose, size_average=False)\n",
    "    cosinesimilarity = Cosine_Similarity(real_CT_transpose, generate_CT_transpose, size_average=False)\n",
    "    ssim = Structural_Similarity(real_CT_transpose, generate_CT_transpose, size_average=False, PIXEL_MAX=1.0)\n",
    "    # CT range 0-4096\n",
    "    generate_CT_transpose = tensor_back_to_unMinMax(generate_CT_transpose, opt.CT_MIN_MAX[0], opt.CT_MIN_MAX[1]).astype(\n",
    "      np.int32)\n",
    "    real_CT_transpose = tensor_back_to_unMinMax(real_CT_transpose, opt.CT_MIN_MAX[0], opt.CT_MIN_MAX[1]).astype(\n",
    "      np.int32)\n",
    "    psnr_3d = Peak_Signal_to_Noise_Rate_3D(real_CT_transpose, generate_CT_transpose, size_average=False, PIXEL_MAX=4095)\n",
    "    psnr = Peak_Signal_to_Noise_Rate(real_CT_transpose, generate_CT_transpose, size_average=False, PIXEL_MAX=4095)\n",
    "    mae = MAE(real_CT_transpose, generate_CT_transpose, size_average=False)\n",
    "    mse = MSE(real_CT_transpose, generate_CT_transpose, size_average=False)\n",
    "\n",
    "    name1 = os.path.splitext(os.path.basename(img_path[0][0]))[0]\n",
    "    name2 = os.path.split(os.path.dirname(img_path[0][0]))[-1]\n",
    "    name = name2 + '_' + name1\n",
    "    print(cosinesimilarity, name)\n",
    "    if cosinesimilarity is np.nan or cosinesimilarity > 1:\n",
    "      print(os.path.splitext(os.path.basename(gan_model.get_image_paths()[0][0]))[0])\n",
    "      continue\n",
    "\n",
    "    metrics_list = [('MAE0', mae0), ('MSE0', mse0), ('MAE', mae), ('MSE', mse), ('CosineSimilarity', cosinesimilarity),\n",
    "                    ('psnr-3d', psnr_3d), ('PSNR-1', psnr[0]),\n",
    "                    ('PSNR-2', psnr[1]), ('PSNR-3', psnr[2]), ('PSNR-avg', psnr[3]),\n",
    "                    ('SSIM-1', ssim[0]), ('SSIM-2', ssim[1]), ('SSIM-3', ssim[2]), ('SSIM-avg', ssim[3])]\n",
    "\n",
    "    for key, value in metrics_list:\n",
    "      if avg_dict.get(key) is None:\n",
    "        avg_dict[key] = [] + value.tolist()\n",
    "      else:\n",
    "        avg_dict[key].extend(value.tolist())\n",
    "\n",
    "    del visuals, img_path\n",
    "\n",
    "  for key, value in avg_dict.items():\n",
    "    print('### --{}-- total: {}; avg: {} '.format(key, len(value), np.round(np.mean(value), 7)))\n",
    "    avg_dict[key] = np.mean(value)\n",
    "\n",
    "  return avg_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1138bdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "  args = parse_args()\n",
    "  evaluate(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
